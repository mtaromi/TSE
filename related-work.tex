%
% 	Related Work
%
\label{sec:related-work}
Here, we provide a discussion of the related efforts in the context of our research.

\subsection{Pre-/Post-conditions-based Testing}
\label{sec:relatd-pre-post}
Scheetz et al.~\cite{Scheetz1999} provides an approach for test generation based on class diagrams. The effects of each method on the state of the system (i.e.,\ post-conditions) are specified by a first order logic language. Test goals are the descriptions of the expected objects' states in the system that are defined manually. Test goals and the system initial state are represented by object diagrams. These models, in addition to the post-conditions of the methods are given to a \textit{planner} that generates a test suite that satisfies the test objectives. This approach is mainly appropriate for systems that has complex state-based behaviour, in contrast to our framework.

Cavarra et al.~\cite{Cavarra2002} present a test generation method based on class, object, and state diagrams. The class diagram identifies the entities in the system and the state diagrams--one for each class--explain how these entities may evolve. The object diagrams are used to describe the initial configuration of the system model, to specify a starting configuration in a test directive, and to flag configurations for inclusion or exclusion in a test model. A state diagram shows how an object will react to the arrival of an event. This method is similar to the method proposed in~\cite{Scheetz1999} except in that the behaviour is modelled by a first order logic language.

Bouquet et al.~\cite{Bouquet2007} defines a subset of UML 2.1~\cite{UML2} that allows formal behaviour models of the SUT. The subset uses class, instance and state diagrams, in addition to OCL~\cite{OCL} expressions. The models are used as input for a model-based test generator, called LEIRIOS Test Designer, that automates--using theorem prover--the generation of test sequences, covering each behaviour in the model. Object diagrams are used to specify the system initial state and test data. The state diagrams are an optional part and used to model the dynamic behaviour of the SUT as a finite state transition system. The OCL language has been extended to support execution semantics. For each test target, an automated theorem prover is used to search for a path from the initial state to that target, and to find data values that satisfy all the constraints along that path. 

\subsection{Static Analysis-based Testing}
\label{sec:relate-static-analysis}
The main idea in~\cite{Engels2006} to raise the abstraction level of the ``design by contract"~\cite{Meyer1992} concept to the level of design models. Each method's functionality is specified by a ``visual contract" --consists of two UML composite structure diagram. One diagram designates the pre-conditions, while the other specifies the post-conditions. Visual contracts are then automatically translated into JML\footnote{JML – Java Modeling Language – \url{http://jmlspecs.org}} assertions in the original code which are monitored, and an exception will be raised upon the violation of a contract. The static analysis techniques are used to automatically find methods' pre-conditions. The main shortcoming of this work is that it does not consider data dependencies. The work differs from the proposed framework in this paper as firstly,  it focus on unit testing and also it uses models for describing pre-/post-conditions. 

The technique presented in~\cite{Maoz2011} allows for QA on static aspects of class diagrams using static analysis. It proposes an extension to object diagrams, namely the ``modal object diagram" that allows defining positive/negative object configurations that the class diagram should allow/disallow. Doing so, each modal object diagram can be considered as a test case that the class diagram should satisfy. Ultimately, the verification is performed by a fully automated model checking-based technique.

The issue of testing UML models as independent from implementation is discussed in~\cite{Andrews2003}. It proposes several testing adequacy criteria for different UML models. The criteria for class diagrams involve creating instances with all possible multiplicities, creating all possible subclasses, and creating objects with different field combinations. A set of coverage criteria are introduced for UML collaboration diagrams including predicate and term coverage of UML guards assigned to message edges, and the execution all the messages and paths. These coverage can automatically be applied on the created models and subsequently result in set of test cases (the latter aspect, however, is not discussed in~\cite{Andrews2003}).


Di Nardo et al.~[Nardo,2017;Nardo, 2015a;Nardo, 2015b] focus on testing data processing software that requires generating complex data files or databases, while ensuring compliance with multiple constraints. The structure and the constraints of input data are modelled by UML class diagrams and OCL constraints. The approach is built upon UML2Alloy [Anastasakis , 2007] to generate an Alloy model that corresponds to the class diagram and the OCL constraints of the data model. The Alloy Analyser is used to generate valid instances of the data model to cover predefined fault types in a fault model.

%Alloy has been  successfully used to analyse Java programs [Jackson, 2000; Khurshid, 2000]. These techniques involve modelling  either the input data structures and computation in Alloy. %The manual translation of non-trivial imperative code into a declarative language is extremely subtle, and required careful thinking. In such approaches, modifications to an implementation require manual remodelling of computation.


\subsection{Specification-based Testing}
\label{sec:related-specification}
Specification-based testing has been intensively considered in the testing literature.  its importance was discussed in a very early paper by Goodenough and Gerhart~\cite{Goodenough1975}.

Different specifications have been considered and used for automatic test generation, such as  Z specifications~\cite{Spivey1992,Horcher1995,Stocks1996,Donat1997}, UML statecharts~\cite{Rumbaugh1999,Offutt1999}, ADL specifications~\cite{Sankar1994,Chang1999}, Alloy specifications~\cite{Jackson2002,Khurshid2004,Coppit2005}, JML specifications~\cite{Boyapati2002}.

Horcher~\cite{Horcher1995} presents a technique for software testing based on Z specifications~\cite{Spivey1992}. This technique provides automated test execution and result evaluation. However, concrete input test data need to be selected manually from an
automatically generated set of test classes.

The UMLTest tool [Offutt, 1999] automatically generates tests from UML statecharts and enabled transitions, but requires all variables to be boolean, among other limiting assumptions it makes about the UML input file. Applied to a C implementation of a cruise control, it detects several faults that were inserted by hand. 

Chang et al~\cite{Chang1999} present a technique for deriving test conditions--a set of boolean conditions on values of parameters--from ADL specifications~\cite{Sankar1994}. These test conditions are used to guide test selection and to measure comprehensiveness of existing test suites.

Boyapati et al.~\cite{Boyapati2002}, introduce Korat, a framework for automated testing of Java programs. Given a formal specification for a method in JML specifications, Korat uses the method pre-conditions and automatically generates all non-isomorphic test cases (within a given input size).The method post-conditions are used as a test oracle to check the correctness of each output.

Khurshid et al.~\cite{Khurshid2004} introduce a framework, called TestEra, for automated specification-based testing of Java programs. TestEra uses the method's pre-condition specification to generate test inputs and the post-condition to check correctness of outputs. TestEra supports specifications written in Alloy and uses the SAT-based back-end of the Alloy tool-set for systematic generation of test cases as JUnit test methods. Our work differs from TestEra for three main reasons: 1) TestEra focuses on unit testing (tests are defined at method level) whereas in our work, use cases and their execution sequence are used for test generation (i.e.,\ acceptance testing), 2) in TestEra, the Alloy specifications are created manually and thus, the testers have to learn to model in Alloy, in contrast to the proposed framework, and 3) TestEra uses the heap memory and thus, is limited to executing time objects, while in our framework, the tester can define any approach for inspection.

\cite{Kaplan2008} presents an approach for automatic test generation using the information provided in the domain and behavioural models of a system. The domain model consists of UML class diagram with invariants, while the behavioural model consists of UML use cases. Each use case flow has an associated guard condition and a set of updates (to the domain object diagram and the output parameters). The approach uses a formal language for modelling and is limited to integer data types. The verification is performed by a set of fault models to mutate an object diagram and a novel algorithm which distinguishes between the original and the mutated object diagrams (kind of conformance testing). Whereas, in our framework, the verification is done by the Inspector component and based on labels which is more flexible than the approach presented in~\cite{Kaplan2008}.

In a later work, Rosner et at.~\cite{Rosner2014} introduces \textsf{HyTeK}, a technique for bounded exhaustive test input generation that automatically generates test suites from input
specifications given in the form of hybrid invariants as such they  may be provided imperatively, declaratively, or as a combination of declarative and imperative predicates. \textsf{HyTeK} benefits  from optimization approaches of each side: (i) the information obtained while solving declarative portions of the invariant assists in pruning the search for partially valid structures from the imperative portion of the specification, and (ii) the \textit{tight bounds} are computed from the declarative invariant and used   during test generation both from the declarative and imperative parts of the specification, to reduce the search space. \textsf{HyTeK} combines a mechanism for processing imperative input specifications introduced in~\cite{Boyapati2002} through the Korat tool, with SAT solving for processing the declarative portions of the input specification, in the style put forward through the tool TestEra~\cite{Khurshid2004}.

%\subsection{MBT in Lightweight Processes}
%\label{sec:related-lightweight}
%\todo{is it required?}