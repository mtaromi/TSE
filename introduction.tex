%
%		Introduction
%
\label{sec:introduction}
\IEEEPARstart{I}{n} the modern software era, testing plays an invaluable role in software development as a quality assurance measure. Estimates have been made that up to 50\% of effort and resources in software projects are allocated to testing. Model based testing (MBT) is one of the important stages of model driven development (MDD), which involves creating test cases from software models. When test cases are created from models, they reside at a higher level of abstraction, therefore creating and maintaining them will cost less, and will utilize more automation possibilities. Also, MBT takes a systematic route to test generation; this allows for a more goal-oriented and direct approach in achieving desirable test coverage criteria, especially when compared to ad-hoc testing. 

Keeping models updated has always been a dire problem in development approaches that are based on models, and MBT is no exception. Also, models that MBT requires, usually involve details that are not considered in normal development processes, or are completely different models from the models developed during general software analysis and design, which only makes this problem worse.

The goal of this research is to introduce a minimal set of structural and behavioural models that can be used as a basis for MBT. The models that are normally produced during the development process, and simple models, developed solely for testing, were given priority. The primary concern in choosing these models was keeping models intuitive and accessible for practitioners, so that the proposed method would require no particular modelling or model-based testing knowledge. 

We have focused on acceptance testing as agile/lightweight methodologies typically consider unit testing and ignore acceptance testing due to associated technical difficulties~\cite{Ambler2008,Ambler}.
%, and secondly, there are several unit testing proposals that can be directly used in such methodologies (e.g.,~\cite{Beck2002,Farago2010a}). 
The proposed approach is in fact an implementation of  the ``Directing testing by modelling the permissible order of operations" and ``Using static analysis" patterns that were introduced for applying MBT in agile/lightweight processes in our earlier work~\cite{Jalalinasab2012}.

In general, automatic acceptance testing techniques are categorised in two types:
\begin{enumerate}
	\item Script-based techniques; based on the informally described requirements and case by case, the use cases developers write tests in a scripting language specified by a testing framework. Examples include the FIT and Cucumber frameworks, used in Acceptance Test Driven Development (ATDD)~\cite{Pugh2011}. However, these techniques suffer from low abstraction level. This results in	brittle, high-maintenance tests which must be developed and maintained individually, and
	
	\item Techniques based on system behavioural models;  use cases (system behaviours) are formalised as behavioural models (e.g.,~\cite{Nebut2006,Sarma2007,Kaplan2008}), implicitly defining the test execution paths for the system under test (SUT). This type of testing is an on-line MBT method. However, in such techniques the required model is often complex, making them inappropriate for agile processes.

\end{enumerate} 

Deriving tests based on behavioural models addresses the main problem with script-based testing--by providing higher level of abstraction. It, however, struggles with complex and inappropriate models for lightweight processes. Accordingly, this paper presents an acceptance testing technique based on system behavioural models, and introduces a set of simple models, so it becomes practical for application in agile processes. Our method uses simple models, in particular class diagrams and use cases--considered as the most useful models~\cite{Erickson2007,Erickson2008}, and is tailored to data-oriented systems.



The proposed testing framework generates tests usign 1) the domain model or the class diagram, as the structural model, 2) use cases, as the behavioural model, and 3) a static analyser (i.e.,\ Alloy~\cite{Jackson2002}) for generating test cases. The models are automatically translated into Alloy specifications. The solutions to the Alloy models are translated into executable test cases.

The focus of the framework is testing the systems that, by large, manage domain objects. Fig.~\ref{fig:framework-structure} shows the overall structure of the proposed framework.

\begin{figure}[!t]
\centering
\includegraphics[width=0.5\textwidth]{../Figures/framework-structure.png}
\caption{Overall structure of the proposed framework.}
\label{fig:framework-structure}
\end{figure}

The effectiveness and applicability of the proposed framework was evaluated by applying the framework in testing a medium-sized business application. The outcome of the case study, including discovered errors and test coverage, was analysed. Various testing coverage, namely line coverage, input coverage, and use case coverage, and mutation testing were used for the analysis.


\textit{Contributions.} This paper makes the following
contributions:
\begin{itemize}
	\item \textit{Lightweight model-based acceptance testing.} We develop a lightweight testing framework with detailed description on how the approach is used from testers' perspective.
	
	\item \textit{Behavioural modelling DSLs.} We develop a set of simple DSLs for behavioural modelling.
	
	\item \textit{Implementation.} We provide the tooling support requires to create test models (DSLs), automatically transform models into Alloy (model transformations), and execute test cases on the SUT (test driver and test harness).
	
	\item \textit{Experiments. } We present results from a case study, and measuring the results using coverage criteria and mutation testing.
\end{itemize}

\textit{Outline.} The remainder of this paper is organized as follows. 
Section~\ref{sec:running-example} explains a running example used to illustrate the testing framework. Section~\ref{sec:framework-overview} provides an overview of the proposed testing framework. Sections~\ref{sec:create-test-model} and~\ref{sec:test-generation-execution} describe the details of creating test models and test generation and execution, respectively. Section~\ref{sec:evaluation} presents the evaluation of the approach. Finally, the paper concludes with a discussion of limitations, and an outline of the related research and future work.
